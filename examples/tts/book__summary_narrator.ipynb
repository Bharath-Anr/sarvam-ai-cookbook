{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Book Summary Narrator**\n",
        "\n",
        "This notebook demonstrates how to use **Sarvam's Text-to-Speech API** effectively. It focuses on building Book summary generator which can help you to get some inspirations to build **innovative and impactful applications**, such as:\n",
        "\n",
        "- **Audiobook generators**\n",
        "- **Accessible content for visually impaired users**\n",
        "- **Automated narration systems for summaries and reports**\n",
        "\n",
        "---\n",
        "\n",
        "## **What This Notebook Covers**\n",
        "\n",
        "This notebook explains how to use **Sarvam's Text-to-Speech API** with Python to create useful applications. It walks you through the entire process:\n",
        "\n",
        "1. **Extracting Text from PDFs**  \n",
        "   Using the `PyPDF2` library to get text from PDF files.\n",
        "\n",
        "2. **Summarizing the Text**  \n",
        "   Using AI to create a concise summary of the extracted text.\n",
        "\n",
        "3. **Converting Text to Speech**  \n",
        "   Using **Sarvam's API** to turn the summary into clear and natural-sounding audio.\n",
        "\n",
        "---\n",
        "\n",
        "## **Key Features**\n",
        "\n",
        "- **Simple Code Examples**: Easy-to-follow Python code for each step.\n",
        "- **End-to-End Process**: From text extraction to audio generation.\n",
        "- **Practical Applications**: Build tools like audiobooks, automated narrators, or accessible content.\n",
        "\n",
        "---\n",
        "\n",
        "## **Why Use This Notebook?**\n",
        "\n",
        "- **Learn API Integration**: Understand how to work with APIs like Sarvam's Text-to-Speech.\n",
        "- **Hands-On Experience**: Get practical experience with text processing and audio generation.\n",
        "- **Build Useful Tools**: Create applications that can help people, like audiobooks for visually impaired users.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AOR9FBCD0c8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installation Commands**\n",
        "### Run these commands to install the necessary libraries before executing the notebook."
      ],
      "metadata": {
        "id": "IEBsFvRvwnmd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqbBthKAPZr9",
        "outputId": "5a9dbe42-bdf1-4473-e848-32ade036a22a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Collecting textwrap3\n",
            "  Downloading textwrap3-0.9.2-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Downloading textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\n",
            "Installing collected packages: textwrap3\n",
            "Successfully installed textwrap3-0.9.2\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.11/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install google-generativeai\n",
        "!pip install requests\n",
        "!pip install textwrap3\n",
        "!pip install pathlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**\n",
        "### Import all the required libraries for the process."
      ],
      "metadata": {
        "id": "5UvA2kuOxZUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import google.generativeai as genai\n",
        "import requests\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import json\n",
        "from textwrap import wrap\n",
        "import time\n",
        "import base64\n"
      ],
      "metadata": {
        "id": "sDtKPmi5xmM_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configure Logging**\n",
        "### Set up logging to track the execution of the script."
      ],
      "metadata": {
        "id": "ALftcUImxr-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('book_narrator.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "JVUDisSDxv44"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SxJSex9LyLY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set Up the API Endpoint and Payload**\n",
        "\n",
        "### To use the Saaras API, you need an API subscription key. Follow these steps to set up your API key:\n",
        "\n",
        "### **1. Obtain your API key**: If you don’t have an API key, sign up on the Sarvam AI Dashboard to get one.\n",
        "### **2. Replace the placeholder key:** In the code below, replace \"YOUR_SARVAM_AI_API_KEY\" and \"YOUR_GEMINI_API_KEY\" with your actual API key.\n"
      ],
      "metadata": {
        "id": "h1Bi_61mx3mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SARVAM_API_KEY = \"YOUR_SARVAM_AI_API_KEY\"\n",
        "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY\"\n",
        "MAX_CHUNK_LENGTH = 500  # Maximum characters per chunk for Text-to-Speech (TTS)"
      ],
      "metadata": {
        "id": "USFy2lQMx7I9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extract Text from PDF**\n",
        "### Function to extract text from a PDF file."
      ],
      "metadata": {
        "id": "Yk2UhvGjyAvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from PDF file.\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text()\n",
        "        logging.info(f\"Successfully extracted text from {pdf_path}\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error extracting text from PDF: {str(e)}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "7BOEWfcMyJZj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generate Summary Using** *Gemini API*\n",
        "### Function to generate a concise summary of text using the Gemini API.\n",
        "\n"
      ],
      "metadata": {
        "id": "fMN31ECqyQ2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text):\n",
        "    \"\"\"Generate summary using Google's Gemini API.\"\"\"\n",
        "    try:\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        model = genai.GenerativeModel('gemini-pro')\n",
        "        prompt = f\"\"\"Please provide a concise summary of the following text. Focus on the main ideas \\\n",
        "        and key points, keeping the summary clear and engaging: {text}\"\"\"\n",
        "        response = model.generate_content(prompt)\n",
        "        logging.info(\"Successfully generated summary using Gemini API\")\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error generating summary: {str(e)}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "3TKPoX_dySWn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Text into Chunks\n",
        "# Function to split text into manageable chunks for TTS processing.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h5OoTrNGyk1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_into_chunks(text, max_length=MAX_CHUNK_LENGTH):\n",
        "    \"\"\"Split text into chunks of maximum length, trying to break at sentence endings.\"\"\"\n",
        "    sentences = text.replace('\\n', ' ').split('. ')\n",
        "    chunks = []\n",
        "    current_chunk = ''\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence != sentences[-1]:\n",
        "            sentence += '.'\n",
        "\n",
        "        if len(current_chunk) + len(sentence) + 1 > max_length:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + ' '\n",
        "        else:\n",
        "            current_chunk += sentence + ' '\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    logging.info(f\"Split text into {len(chunks)} chunks\")\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "D0VXTQjmyq3F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Text to Speech Using Sarvam API\n",
        "# Function to convert text to speech using Sarvam API."
      ],
      "metadata": {
        "id": "qNTOgV31y45Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_speech(text, output_path, language_code=\"en-IN\"):\n",
        "    \"\"\"Convert text to speech using Sarvam AI API.\"\"\"\n",
        "    url = \"https://api.sarvam.ai/text-to-speech\"\n",
        "\n",
        "    payload = {\n",
        "        \"inputs\": [text],\n",
        "        \"target_language_code\": language_code,\n",
        "        \"speaker\": \"amartya\",  # Male voice\n",
        "        \"pitch\": 0,\n",
        "        \"pace\": 1.0,\n",
        "        \"loudness\": 1.2,\n",
        "        \"speech_sample_rate\": 22050,\n",
        "        \"enable_preprocessing\": True,\n",
        "        \"model\": \"bulbul:v1\"\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"Accept\": \"application/json\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-subscription-key\": SARVAM_API_KEY\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        logging.info(f\"Sending request to Sarvam API for chunk of length {len(text)}\")\n",
        "        response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "        logging.info(f\"Sarvam API Response Status Code: {response.status_code}\")\n",
        "\n",
        "        response.raise_for_status()\n",
        "\n",
        "        audio_data = response.json()\n",
        "\n",
        "        if \"audios\" in audio_data:\n",
        "            base64_audio = audio_data[\"audios\"][0]\n",
        "            binary_audio = base64.b64decode(base64_audio)\n",
        "\n",
        "            with open(output_path, 'wb') as f:\n",
        "                f.write(binary_audio)\n",
        "            logging.info(f\"Successfully saved audio file to {output_path}\")\n",
        "            return True\n",
        "        else:\n",
        "            logging.error(\"No audio data found in response.\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error converting text to speech: {str(e)}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "Jy5mXgDAzBzB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process Book Workflow\n",
        "# Main function to extract text, generate a summary, and create an audio narration."
      ],
      "metadata": {
        "id": "0yPS9ADJzFq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_book(pdf_path, output_dir=\"output\"):\n",
        "    \"\"\"Process book: Extract text, generate summary, and create audio.\"\"\"\n",
        "    try:\n",
        "        Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "        logging.info(f\"Processing book from {pdf_path}\")\n",
        "\n",
        "        logging.info(\"Starting text extraction...\")\n",
        "        book_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "        text_path = os.path.join(output_dir, \"extracted_text.txt\")\n",
        "        with open(text_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(book_text)\n",
        "        logging.info(f\"Text extracted and saved to {text_path}\")\n",
        "\n",
        "        logging.info(\"Starting summary generation...\")\n",
        "        summary = generate_summary(book_text)\n",
        "\n",
        "        summary_path = os.path.join(output_dir, \"summary.txt\")\n",
        "        with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(summary)\n",
        "        logging.info(f\"Summary generated and saved to {summary_path}\")\n",
        "\n",
        "        chunks = split_text_into_chunks(summary)\n",
        "        audio_files = []\n",
        "\n",
        "        for i, chunk in enumerate(chunks, 1):\n",
        "            logging.info(f\"Processing chunk {i} of {len(chunks)}\")\n",
        "            audio_path = os.path.join(output_dir, f\"summary_narration_part_{i}.wav\")\n",
        "            text_to_speech(chunk, audio_path)\n",
        "            audio_files.append(audio_path)\n",
        "            if i < len(chunks):\n",
        "                time.sleep(1)\n",
        "\n",
        "        return {\n",
        "            \"text_path\": text_path,\n",
        "            \"summary_path\": summary_path,\n",
        "            \"audio_files\": audio_files\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing book: {str(e)}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "0EUGUAfIzGKW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute the Workflow\n",
        "# Provide the path to the PDF file you want to process.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-VXKjsZ-zQw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    pdf_path = \"cheese.pdf\"  # Replace with the actual file path\n",
        "    logging.info(f\"Starting processing of PDF: {pdf_path}\")\n",
        "    results = process_book(pdf_path)\n",
        "    logging.info(\"\\nProcessing completed successfully!\")\n",
        "    logging.info(f\"Text file: {results['text_path']}\")\n",
        "    logging.info(f\"Summary file: {results['summary_path']}\")\n",
        "    logging.info(\"Audio files:\")\n",
        "    for audio_file in results['audio_files']:\n",
        "        logging.info(f\"- {audio_file}\")"
      ],
      "metadata": {
        "id": "vUOVjfjKzSJN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Additional Resources**\n",
        "\n",
        "For more details, refer to the official **Sarvam AI API documentation** and join the community for support:\n",
        "\n",
        "- **Documentation**: [docs.sarvam.ai](https://docs.sarvam.ai/)\n",
        "- **Community**: [Join the Discord Community](https://discord.gg/hTuVuPNF)\n",
        "\n",
        "### **Notes:**\n",
        "\n",
        "**File Format:** Ensure the file is in .wav format and has a sample rate of 16kHz.\n",
        "\n",
        "**API Key:** Double-check that the SARVAM_API_KEY is correctly set.\n",
        "\n",
        "**Error Handling:** If transcription fails, the error message and response content will be displayed for debugging.\n",
        "\n",
        "**Keep Building!** 🚀\n"
      ],
      "metadata": {
        "id": "BI8o4zN32E6u"
      }
    }
  ]
}